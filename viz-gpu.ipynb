{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 20 20:08:21 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0    40W / 300W |  15239MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import build_model, normalize_img\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipelines(num_train_examples, num_test_examples):\n",
    "    \"\"\"\n",
    "    Builds the training and test set\n",
    "    \"\"\"\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        \"mnist\",\n",
    "        split=[\"train\", \"test\"],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "\n",
    "    ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE).take(\n",
    "        num_train_examples\n",
    "    )\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(num_train_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE).take(\n",
    "        num_test_examples\n",
    "    )\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds_train, ds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(i, num_train_examples=60000, num_test_examples=10000):\n",
    "    \"\"\"\n",
    "    Trains an model on the MNIST dataset given the number of training and test examples\n",
    "    \"\"\"\n",
    "    ds_train, ds_test = build_pipelines(num_train_examples, num_test_examples)\n",
    "    model = build_model()\n",
    "    model.fit(ds_train, epochs=6, validation_data=ds_test, verbose=0)\n",
    "    _, test_accuracy = model.evaluate(ds_test, verbose=0)\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Training Set, Fixed Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 18:28:13.128572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.138323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.139043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.140222: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-20 18:28:13.140554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.141239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.141818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.715321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.716068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.716699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.717276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14634 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
      "2021-11-20 18:28:14.442282: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:18.127623: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:22.436935: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:26.989556: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:31.812006: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:35.888858: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:40.277507: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:44.650719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:49.041416: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:53.495789: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:57.866632: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:02.353961: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:06.754834: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:11.410207: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:15.838793: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:20.379456: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:24.824117: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:29.549338: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:34.034367: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:38.292624: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:42.656741: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:46.855355: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:51.323098: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:55.712899: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:00.573446: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:04.092390: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:11.540272: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:15.882237: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:20.297240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:01:54.963690: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:09.949833: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:21.429977: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:31.703520: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:41.975105: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:51.934617: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:02.147301: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:13.192423: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:22.815668: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:36.316456: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:45.936787: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:55.238324: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:04:03.880596: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:04:14.003723: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:04:24.199303: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58min 23s, sys: 24min 21s, total: 1h 22min 44s\n",
      "Wall time: 1h 5min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Training Set Size'), Text(0, 0.5, 'Test Accuracy')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "trials = 100\n",
    "\n",
    "training_size = [1000, 10000, 30000, 60000]\n",
    "test_size = 10000\n",
    "\n",
    "data = [[run_experiment(i, ts, test_size) for i in range(trials)] for ts in training_size]\n",
    "\n",
    "col_names = [str(f\"{i:,}\") for i in training_size]\n",
    "df = pd.DataFrame(data).transpose()\n",
    "df.columns = col_names\n",
    "\n",
    "df.boxplot(col_names, figsize=(10,10))\\\n",
    "    .set(xlabel=\"Training Set Size\", ylabel=\"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Training Set, Variable Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 20:11:25.150408: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:25.944704: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:32.548502: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:33.307716: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:39.888094: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:40.711230: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:48.365673: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:49.178230: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:56.404344: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:57.196280: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:04.305924: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:05.048050: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:13.296675: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:14.108071: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:23.139747: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:25.587488: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:39.972535: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:41.423792: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:51.838944: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:52.633658: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:00.031719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:00.812654: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:10.926842: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:11.722550: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:24.657152: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:25.496406: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:32.751736: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:33.544531: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:41.988167: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:42.824508: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:50.427222: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:51.272891: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:00.249949: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:01.097417: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:12.344287: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:14.137350: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:23.578070: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:24.911148: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:40.402804: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:41.315293: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:48.373194: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:49.111514: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:57.156630: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:14:58.011363: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:06.757774: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:07.646577: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:14.897461: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:15.886216: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:27.142881: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:28.015465: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:37.147116: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:38.109520: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:46.463042: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:47.335809: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:54.773083: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:15:55.621901: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:02.026627: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:02.837215: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:09.396172: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:10.204770: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:17.591061: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:18.401593: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:25.856708: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:26.650141: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:33.444399: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:34.296300: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:42.322169: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:43.168606: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:49.807316: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:50.847878: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:58.076881: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:16:59.128494: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:05.697628: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:06.528345: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:13.399160: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:14.188800: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:26.965713: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:27.810190: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:39.567298: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:40.379510: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:48.256631: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:49.031457: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:56.558460: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:17:57.372950: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:04.068773: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:04.921046: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:13.784783: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:14.607441: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:23.043276: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:23.919129: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:31.417372: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:32.285687: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:39.628531: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:40.429321: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:46.822506: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:47.628734: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:55.675702: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:18:56.400421: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:05.206188: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:06.048085: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:13.029583: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:13.788281: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:22.455171: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:24.683770: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:33.283717: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:34.129215: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:41.748256: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:42.593899: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:49.758211: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:50.593872: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:19:59.176151: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:00.070824: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:08.003555: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:08.870768: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:15.378305: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:16.168394: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:22.920139: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:23.655365: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:31.365778: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:32.177488: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:39.910375: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:40.772608: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:48.315295: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:49.201353: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:55.665379: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:20:56.478591: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:03.093839: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:03.884002: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:12.498695: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:13.360459: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:21.129826: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:22.844723: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:34.149578: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:34.895937: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:43.486806: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:44.411745: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:51.761001: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:21:52.657354: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:01.033600: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:01.875253: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:09.131578: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:09.903232: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:17.675141: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:18.418993: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:24.604527: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:25.403294: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:33.787242: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:34.645750: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:42.081584: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:42.907054: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:50.547286: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:51.310370: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:58.100247: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:22:58.953471: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:07.225477: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:08.446818: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:16.645018: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:17.389421: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:26.790213: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:29.777045: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:41.115629: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:42.510626: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:53.579897: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:23:54.384082: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:01.486736: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:02.333295: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:10.193898: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:11.064035: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:18.411493: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:19.289522: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:27.025941: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:27.832320: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:36.384843: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:37.462559: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:44.721931: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:45.516453: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:53.560235: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:24:54.398832: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:02.030524: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:02.853262: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:10.963766: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:11.929190: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:19.839048: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:20.699658: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:30.777551: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:33.267339: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:40.975195: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:41.814537: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:49.806818: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:50.566250: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:58.367339: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:25:59.134995: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:05.838159: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:06.604194: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:14.414535: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:15.203492: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:23.181012: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:23.897679: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:31.582108: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:32.366414: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:40.220817: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:41.516128: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:49.840757: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:51.053858: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:57.826158: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:26:59.063029: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:06.375596: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:07.600660: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:14.847219: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:16.055466: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:23.505262: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:24.725843: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:38.199177: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:39.449916: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:47.326113: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:48.496012: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:56.425504: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:27:57.684867: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:06.722422: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:08.029140: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:16.135974: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:17.356248: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:26.077102: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:27.457605: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:36.606694: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:37.889904: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:46.000445: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:47.265361: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:55.862486: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:28:57.066830: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:04.648260: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:05.889275: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:13.811775: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:15.127836: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:25.471265: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:26.662057: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:41.821396: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:43.093631: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:50.676623: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:29:52.017082: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:00.049178: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:01.250171: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:08.519542: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:09.820458: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:18.585879: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:19.707333: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:27.576505: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:28.856962: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:37.599908: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:38.799666: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:46.126142: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:47.504599: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:56.265546: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:30:57.581945: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:05.019213: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:06.351534: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:13.637591: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:14.972324: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:25.210373: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:26.413407: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:35.523502: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:38.340124: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:48.892963: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:50.073149: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:58.031918: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:31:59.350801: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:08.149163: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:09.403398: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:18.136017: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:19.386331: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:26.761826: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:27.994537: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:36.421324: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:37.798978: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:45.472519: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:46.690288: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:53.970052: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:32:55.354043: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:02.666409: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:03.948727: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:12.013843: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:13.302139: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:21.286546: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:22.530311: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:30.888891: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:32.253181: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:48.082567: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:49.323138: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:56.016477: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:33:57.225773: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:04.728425: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:06.007186: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:13.561988: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:14.880524: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:24.263115: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:25.579541: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:34.611729: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:35.855917: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:43.952918: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:45.206152: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:53.348300: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:34:54.619403: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:02.825281: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:04.101348: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:12.125395: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:13.436150: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:21.286238: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:22.572083: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:33.649398: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:34.848602: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:49.279080: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:35:50.598733: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:03.101233: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:04.297080: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:12.603330: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:13.834360: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:22.356202: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:23.658078: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:31.306410: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:32.502038: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:41.531635: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:42.839303: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:51.133160: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:36:52.409247: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:00.281932: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:01.432322: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:10.798290: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:12.079364: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:20.519448: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:21.838445: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:29.278151: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:31.292460: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:45.310337: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:48.023115: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:37:58.878593: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:00.264741: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:08.548958: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:09.728097: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:19.205257: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:20.592014: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:28.177268: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:29.416927: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:36.857499: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:38.098799: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:46.792432: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:48.074177: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:56.350704: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:38:57.582617: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:04.993924: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:06.371627: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:13.678971: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:14.894806: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:21.705863: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:22.969482: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:33.280235: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:34.508322: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:41.292776: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:42.562139: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:57.827718: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:39:58.971408: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:10.462685: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:11.787671: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:19.291005: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:20.485892: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:27.993932: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:29.309103: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:36.142387: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:37.423764: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:45.350819: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:46.561159: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:53.634831: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:40:54.933874: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:02.502066: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:03.766713: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:12.581726: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:13.946379: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:23.797323: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:26.429693: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:38.587562: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:39.895969: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:47.179348: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:41:48.477201: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:00.727603: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:01.911239: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:09.933947: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:11.222048: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:17.846791: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:19.102546: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:26.659684: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:28.019318: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:35.432722: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:36.616697: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:43.974504: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:45.208163: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:52.467243: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:42:53.718712: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:43:01.280865: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:43:02.487827: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:43:10.832876: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:43:12.023509: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:43:21.347261: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:43:30.758836: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:43:41.513922: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:43:51.474884: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:44:05.741916: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:44:15.291674: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:44:25.158717: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:44:35.621796: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:44:45.280433: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:44:54.856173: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:45:04.938423: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:45:27.411133: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:45:39.809199: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:45:49.391271: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:46:03.158004: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:46:17.264904: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:46:28.103829: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:46:38.815938: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:46:49.129028: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:46:59.377664: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:47:08.904439: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:47:19.379557: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:47:34.601360: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:47:45.614271: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:47:56.740517: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:48:14.188355: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:48:26.085379: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:48:36.822638: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:48:47.714412: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:49:02.846238: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:49:13.108056: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:49:23.974633: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:49:35.831457: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:49:46.209786: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:49:57.121161: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:50:11.685670: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:50:25.433510: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:50:35.945164: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:50:44.985317: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:50:54.638468: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:51:04.477108: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:51:14.823636: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:51:31.148810: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:51:41.586992: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:51:52.346000: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:52:03.820208: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:52:21.520159: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:52:31.811888: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:52:42.612899: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:52:53.665484: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:53:04.427428: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:53:15.237463: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:53:25.195847: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:53:34.155605: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:53:44.602438: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:53:54.630176: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:54:07.267599: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:54:24.609115: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:54:36.355922: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:54:46.681649: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:54:56.679059: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:55:07.595283: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:55:18.431358: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:55:28.462565: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:55:38.393832: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:55:49.069198: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:56:05.335905: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:56:15.596243: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:56:32.014930: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:56:41.280652: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:56:51.864722: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:57:02.166065: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:57:11.803660: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:57:22.629489: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:57:32.850685: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:57:43.444787: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:57:53.059710: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:58:07.749646: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:58:18.628040: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:58:36.290961: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:58:51.837497: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:59:07.966829: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:59:23.566369: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:59:34.300129: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:59:44.838652: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:59:56.662689: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:00:14.923470: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:00:35.781162: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:00:47.255562: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:01:03.360554: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:01:14.896734: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:01:30.774167: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:01:42.556979: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:01:53.564756: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:02:03.761012: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:02:22.766197: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:02:42.638124: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:02:54.543316: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:03:10.383365: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 21:03:26.556841: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 1s, sys: 18min 34s, total: 1h 3min 35s\n",
      "Wall time: 52min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Test Set Size'), Text(0, 0.5, 'Test Accuracy')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "trials = 100\n",
    "\n",
    "training_size = 30000\n",
    "test_size = [1000, 5000, 10000]\n",
    "\n",
    "data = [[run_experiment(i, training_size, ts) for i in range(trials)] for ts in test_size]\n",
    "\n",
    "col_names = [str(f\"{i:,}\") for i in test_size]\n",
    "df = pd.DataFrame(data).transpose()\n",
    "df.columns = col_names\n",
    "\n",
    "df.boxplot(col_names, figsize=(10,10))\\\n",
    "    .set(xlabel=\"Test Set Size\", ylabel=\"Test Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

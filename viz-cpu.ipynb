{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "Address sizes:                   46 bits physical, 48 bits virtual\n",
      "CPU(s):                          2\n",
      "On-line CPU(s) list:             0,1\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              1\n",
      "Socket(s):                       1\n",
      "NUMA node(s):                    1\n",
      "Vendor ID:                       GenuineIntel\n",
      "CPU family:                      6\n",
      "Model:                           79\n",
      "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "Stepping:                        0\n",
      "CPU MHz:                         2199.998\n",
      "BogoMIPS:                        4399.99\n",
      "Hypervisor vendor:               KVM\n",
      "Virtualization type:             full\n",
      "L1d cache:                       32 KiB\n",
      "L1i cache:                       32 KiB\n",
      "L2 cache:                        256 KiB\n",
      "L3 cache:                        55 MiB\n",
      "NUMA node0 CPU(s):               0,1\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
      "Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT Host state u\n",
      "                                 nknown\n",
      "Vulnerability Meltdown:          Mitigation; PTI\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled v\n",
      "                                 ia prctl and seccomp\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user\n",
      "                                  pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Full generic retpoline, IBPB condit\n",
      "                                 ional, IBRS_FW, STIBP conditional, RSB filling\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Mitigation; Clear CPU buffers; SMT Host state u\n",
      "                                 nknown\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
      "                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s\n",
      "                                 se2 ss ht syscall nx pdpe1gb rdtscp lm constant\n",
      "                                 _tsc rep_good nopl xtopology nonstop_tsc cpuid \n",
      "                                 tsc_known_freq pni pclmulqdq ssse3 fma cx16 pci\n",
      "                                 d sse4_1 sse4_2 x2apic movbe popcnt aes xsave a\n",
      "                                 vx f16c rdrand hypervisor lahf_lm abm 3dnowpref\n",
      "                                 etch invpcid_single pti ssbd ibrs ibpb stibp fs\n",
      "                                 gsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms \n",
      "                                 invpcid rtm rdseed adx smap xsaveopt arat md_cl\n",
      "                                 ear arch_capabilities\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import build_model, normalize_img\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipelines(num_train_examples, num_test_examples):\n",
    "    \"\"\"\n",
    "    Builds the training and test set\n",
    "    \"\"\"\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        \"mnist\",\n",
    "        split=[\"train\", \"test\"],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "\n",
    "    ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE).take(\n",
    "        num_train_examples\n",
    "    )\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(num_train_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE).take(\n",
    "        num_test_examples\n",
    "    )\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds_train, ds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(i, num_train_examples=60000, num_test_examples=10000):\n",
    "    \"\"\"\n",
    "    Trains an model on the MNIST dataset given the number of training and test examples\n",
    "    \"\"\"\n",
    "    ds_train, ds_test = build_pipelines(num_train_examples, num_test_examples)\n",
    "    model = build_model()\n",
    "    model.fit(ds_train, epochs=6, validation_data=ds_test, verbose=0)\n",
    "    _, test_accuracy = model.evaluate(ds_test, verbose=0)\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Training Set, Fixed Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 18:28:13.128572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.138323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.139043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.140222: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-20 18:28:13.140554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.141239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.141818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.715321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.716068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.716699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 18:28:13.717276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14634 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
      "2021-11-20 18:28:14.442282: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:18.127623: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:22.436935: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:26.989556: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:31.812006: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:35.888858: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:40.277507: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:44.650719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:49.041416: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:53.495789: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:28:57.866632: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:02.353961: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:06.754834: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:11.410207: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:15.838793: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:20.379456: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:24.824117: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:29.549338: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:34.034367: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:38.292624: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:42.656741: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:46.855355: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:51.323098: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:29:55.712899: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:00.573446: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:04.092390: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:11.540272: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:15.882237: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 18:30:20.297240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:01:54.963690: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:09.949833: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:21.429977: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:31.703520: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:41.975105: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:02:51.934617: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:02.147301: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:13.192423: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:22.815668: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:36.316456: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:45.936787: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:03:55.238324: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:04:03.880596: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:04:14.003723: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 19:04:24.199303: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58min 23s, sys: 24min 21s, total: 1h 22min 44s\n",
      "Wall time: 1h 5min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Training Set Size'), Text(0, 0.5, 'Test Accuracy')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "trials = 100\n",
    "\n",
    "training_size = [1000, 10000, 30000, 60000]\n",
    "test_size = 10000\n",
    "\n",
    "data = [[run_experiment(i, ts, test_size) for i in range(trials)] for ts in training_size]\n",
    "\n",
    "col_names = [str(f\"{i:,}\") for i in training_size]\n",
    "df = pd.DataFrame(data).transpose()\n",
    "df.columns = col_names\n",
    "\n",
    "df.boxplot(col_names, figsize=(10,10))\\\n",
    "    .set(xlabel=\"Training Set Size\", ylabel=\"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Training Set, Variable Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 20:11:25.150408: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:25.944704: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:32.548502: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:33.307716: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:39.888094: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:40.711230: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:48.365673: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:49.178230: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:56.404344: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:11:57.196280: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:04.305924: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:05.048050: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:13.296675: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:14.108071: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:23.139747: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:25.587488: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:39.972535: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:41.423792: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:51.838944: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:12:52.633658: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:00.031719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:00.812654: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:10.926842: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-20 20:13:11.722550: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trials = 100\n",
    "\n",
    "training_size = 30000\n",
    "test_size = [1000, 5000, 10000]\n",
    "\n",
    "data = [[run_experiment(i, training_size, ts) for i in range(trials)] for ts in test_size]\n",
    "\n",
    "col_names = [str(f\"{i:,}\") for i in test_size]\n",
    "df = pd.DataFrame(data).transpose()\n",
    "df.columns = col_names\n",
    "\n",
    "df.boxplot(col_names, figsize=(10,10))\\\n",
    "    .set(xlabel=\"Test Set Size\", ylabel=\"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume 1,000 training examples and only 500 test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trials = 100\n",
    "\n",
    "training_size = 1000\n",
    "test_size = 500\n",
    "\n",
    "data = [run_experiment(i, training_size, test_size) for i in range(trials)]\n",
    "\n",
    "df = pd.DataFrame({f\"{test_size:,}\": data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that with if we have access to the full test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trials = 100\n",
    "\n",
    "training_size = 1000\n",
    "test_size = 10000\n",
    "\n",
    "data = [run_experiment(i, training_size, test_size) for i in range(trials)]\n",
    "\n",
    "df_full = pd.DataFrame({f\"{test_size:,}\": data})\n",
    "\n",
    "df_comb = pd.concat([df, df_full], ignore_index=True, join=\"outer\", axis=1)\n",
    "df_comb.columns = [\"500\", \"10,000\"]\n",
    "\n",
    "# visualize the results side-by-side\n",
    "df_comb.boxplot(figsize=(10,10))\\\n",
    "    .set(xlabel=\"Test Set Size\", ylabel=\"Test Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
